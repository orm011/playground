{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from tqdm.auto import tqdm\n",
    "from playground.preprocessing import clip_model, clip_processor, model_device\n",
    "\n",
    "# for experiments\n",
    "from sklearn import svm, linear_model\n",
    "from sklearn.metrics import average_precision_score\n",
    "from playground.linear_model import LinearModel\n",
    "import importlib\n",
    "import playground.linear_model\n",
    "importlib.reload(playground.linear_model)\n",
    "from playground.linear_model import LinearModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute embedding first time: this will take a few minutes\n",
    "## need to download objectnet first (and crop 224x224)\n",
    "#from playground.load import objectnet_dataset, extract_image_vectors\n",
    "#df = extract_image_vectors(objectnet_dataset)\n",
    "#df.to_parquet('data/objectnet/embeddings.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load precomputed embeddings\n",
    "objectnet_df = pd.read_parquet('data/objectnet/embeddings.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "# work with unit length vectors for dot product (works better for CLIP embeddings)\n",
    "objectnet_df = objectnet_df.assign(normalized_vectors=[vec for vec in np.stack(objectnet_df['vectors']) / np.linalg.norm(objectnet_df['vectors'])])\n",
    "\n",
    "# pick a random image from each class to be the query, the rest will be the test database\n",
    "np.random.seed(13)\n",
    "objectnet_df = objectnet_df.assign(random_id=np.random.permutation(objectnet_df.shape[0]))\n",
    "objectnet_df = objectnet_df.assign(group_rank=objectnet_df.groupby('label')['random_id'].rank(method='first').astype('int'))\n",
    "objectnet_df = objectnet_df.assign(split=objectnet_df.group_rank.apply(lambda x: 'query' if x <= 11 else 'test'))\n",
    "\n",
    "search_query_df = objectnet_df[objectnet_df.split == 'query']\n",
    "test_df = objectnet_df[objectnet_df.split == 'test']\n",
    "\n",
    "# from the test set, take a random sample of the DB which we will use as pseudo-negative examples\n",
    "# while training some of the linear models\n",
    "number_svm_train_examples = 1000\n",
    "random_sample = np.random.permutation(test_df.shape[0])[:number_svm_train_examples]\n",
    "Xneg = np.stack(test_df.iloc[random_sample].normalized_vectors.values)\n",
    "yneg = np.zeros(Xneg.shape[0])\n",
    "\n",
    "# the full test set used for evaluation\n",
    "Xtest = np.stack(test_df.normalized_vectors.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ys(df, label : str):\n",
    "    ''' get binary labels for a given class '''\n",
    "    assert label in df.label.unique()\n",
    "    return np.where(df.label == label, 1, 0)\n",
    "\n",
    "def get_text_embedding(text : str, prompt_template='A picture of a {}'):\n",
    "    ''' get CLIP vector representation of text query '''\n",
    "    text = text.replace('_', ' ')\n",
    "    text = prompt_template.format(text)\n",
    "    query_tokens = clip_processor(text=[text], return_tensors='pt')\n",
    "    query_vector = clip_model.get_text_features(query_tokens['input_ids'].to(model_device))\n",
    "    query_vector = F.normalize(query_vector)\n",
    "    query_vector = query_vector.cpu().detach().numpy().reshape(-1)\n",
    "    return query_vector\n",
    "\n",
    "def eval_method(query_df, vector_function):\n",
    "    ''' run a given functrion over different categories on the dataset and compute AP '''\n",
    "    aps = []\n",
    "    for (idx, row) in tqdm(query_df.iterrows(), total=query_df.shape[0]):\n",
    "        query_vector = vector_function(row)\n",
    "        scores = Xtest @ query_vector\n",
    "        y_true = get_ys(test_df, row.label)\n",
    "        ap = average_precision_score(y_true, scores)\n",
    "        aps.append(ap)\n",
    "    return np.array(aps)\n",
    "\n",
    "\n",
    "## Different methods to get a vector which we can use as a query for the image search\n",
    "\n",
    "def get_vector_from_text(row):\n",
    "    ''' get CLIP vector representation of text query, aka zero-shot search '''\n",
    "    # (simply return the vector rep. of the text query)\n",
    "    return get_text_embedding(row.label)\n",
    "\n",
    "def get_vector_from_knn(row):\n",
    "    ''' get the vector representation of the row, aka nearest neighbor search '''\n",
    "    # (simply return the vector rep. of the image)\n",
    "    return row.normalized_vectors\n",
    "\n",
    "def get_vector_from_exemplar_svm(row):\n",
    "    ''' ExemplarSVM: get the vector representation from using one positive example, and a random sample\n",
    "    labeled as negative, train using SVM and use this for the vector lookup '''\n",
    "    clf = svm.LinearSVC(class_weight='balanced', verbose=False, max_iter=10000, tol=1e-6, C=1.)\n",
    "    Xpos = row.normalized_vectors.reshape(1, -1)\n",
    "    X = np.concatenate([Xpos, Xneg], axis=0)\n",
    "    y = np.concatenate([np.ones(1), yneg])\n",
    "    clf.fit(X, y)\n",
    "    return clf.coef_.reshape(-1)\n",
    "\n",
    "def get_vector_from_exemplar_logistic_reg(row, C):\n",
    "    ''' Similar to ExemplarSVM, but using logistic regression instead.'''\n",
    "    # fit_intercept=False is important for this LR to work nearly as well as SVM\n",
    "    clf = linear_model.LogisticRegression(class_weight='balanced', fit_intercept=False, verbose=False, max_iter=10000, tol=1e-6, C=C)\n",
    "    Xpos = row.normalized_vectors.reshape(1, -1)\n",
    "    random_sample = np.random.permutation(test_df.shape[0])[:number_svm_train_examples]\n",
    "    Xneg = np.stack(test_df.iloc[random_sample].normalized_vectors.values)\n",
    "    yneg = np.zeros(Xneg.shape[0])\n",
    "    X = np.concatenate([Xpos, Xneg], axis=0)\n",
    "    y = np.concatenate([np.ones(1), yneg])\n",
    "    clf.fit(X, y)\n",
    "    return clf.coef_.reshape(-1)\n",
    "\n",
    "def get_vector_from_exemplar_svm_plus_text_reg(row):\n",
    "    ''' Similar to ExemplarSVM, but using a linear model with a regularizer term based on the text query '''\n",
    "    regularizer_vector  = get_vector_from_text(row)\n",
    "    clf = LinearModel(class_weight='balanced', label_loss_type='hinge_squared_loss', reg_norm_lambda=1.,\n",
    "                      verbose=False, max_iter=3,\n",
    "                      regularizer_vector=regularizer_vector, reg_vector_lambda=1000.)\n",
    "    Xpos = row.normalized_vectors.reshape(1, -1)\n",
    "    random_sample = np.random.permutation(test_df.shape[0])[:number_svm_train_examples]\n",
    "    Xneg = np.stack(test_df.iloc[random_sample].normalized_vectors.values)\n",
    "    yneg = np.zeros(Xneg.shape[0])\n",
    "    X = np.concatenate([Xpos, Xneg], axis=0)\n",
    "    y = np.concatenate([np.ones(1), yneg])\n",
    "    clf.fit(X, y) # train\n",
    "    coeff = clf._module.weight.detach().cpu().numpy().reshape(-1)\n",
    "    return coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3443/3443 [05:55<00:00,  9.69it/s]  \n",
      "100%|██████████| 3443/3443 [00:51<00:00, 66.55it/s]\n"
     ]
    }
   ],
   "source": [
    "text_ap = eval_method(search_query_df, get_vector_from_text)\n",
    "knn_ap = eval_method(search_query_df, get_vector_from_knn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3443/3443 [12:49<00:00,  4.47it/s]   \n"
     ]
    }
   ],
   "source": [
    "svm_ap = eval_method(search_query_df, get_vector_from_exemplar_svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3443/3443 [24:35<00:00,  2.33it/s]   \n"
     ]
    }
   ],
   "source": [
    "svm_reg_ap = eval_method(search_query_df, get_vector_from_exemplar_svm_plus_text_reg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "svm_ap        0.099397\n",
       "svm_reg_ap    0.250966\n",
       "knn_ap        0.094210\n",
       "text_ap       0.237345\n",
       "dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.5832123148417078"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8071449317455707"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "search_query_df = search_query_df.assign(svm_ap=svm_ap,  svm_reg_ap=svm_reg_ap,\n",
    "                                         knn_ap=knn_ap, text_ap=text_ap\n",
    "                                         )\n",
    "by_query = search_query_df\n",
    "display(by_query[['svm_ap', 'svm_reg_ap','knn_ap','text_ap']].mean())\n",
    "\n",
    "display((by_query.svm_ap > by_query.knn_ap).mean())\n",
    "display((by_query.svm_reg_ap > by_query.text_ap).mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pixeltable_39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
